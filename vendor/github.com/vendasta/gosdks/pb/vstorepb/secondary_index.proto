syntax = "proto3";

package vstorepb;


message SecondaryIndexPropertyConfig {

    message ElasticsearchField {
        string name = 1;
        string type = 2;
        string index = 3;
    }
    // Elasticsearch Property Config
    message Elasticsearch {
        string type = 1;
        string index = 2;

        // Allows fields to be stored multiple times with different analyzers
        repeated ElasticsearchField fields = 3;

    }

    message CloudSQL {
        string type = 1;
    }

    oneof config {
        Elasticsearch elasticsearch_property_config = 1;
        CloudSQL cloudsql_property_config = 2;
    }
}


message SecondaryIndex {

    // Name of the secondary index, this name must be unique from other secondary indexes
    string name = 1;

    // Index configuration and denotes the type of the secondary index as well.
    oneof index {
        ElasticsearchRawConfig es_raw_config = 2; // Deprecated.
        ElasticsearchConfig es_config = 3;
        CloudSQLConfig cloud_sql_config = 4;
    }
}

message ElasticsearchRawConfig {
    string mapping_json = 1;
    string settings_json = 2;
    string index_name = 3;
}

message ElasticsearchConfig {
    int64 number_of_shards = 1;
    int64 number_of_replicas = 2;
    string refresh_interval = 3;
    ElasticsearchAnalysis analysis = 4;
    string index_name = 5;
}

message CloudSQLConfig {
    string index_name = 1;
    string instance_ip = 2;
    string user_name = 3;
    string password = 4;
    bytes client_key = 5;
    bytes client_cert = 6;
    bytes server_certificate_authority = 7;
    string project_id = 8;
    string instance_name = 9;
}

// https://www.elastic.co/guide/en/elasticsearch/guide/current/custom-analyzers.html
message ElasticsearchAnalysis {
    repeated ElasticsearchAnalyzer analyzers = 1;
    repeated ElasticsearchFilter filters = 2;
    repeated ElasticsearchCharFilter char_filters = 3;
    repeated ElasticsearchTokenizer tokenizers = 4;
}

// ElasticsearchAnalyzer configures a custom analyzer that can be built to transform your data into a
// configuration that suites your particular needs.
message ElasticsearchAnalyzer {
    string name = 1;
    string type = 2;
    repeated string stem_exclusion = 3;
    repeated string stop_words = 4;
    repeated string char_filter = 5;
    string tokenizer = 6;
    repeated string filter = 7;
}

// Token filters may change, add, or remove tokens.
message ElasticsearchFilter {
    string name = 1;
    string type = 2;
    string pattern = 3;
    string replacement = 4;
    repeated string synonyms = 5;
}

// Character filters are used to “tidy up” a string before it is tokenized.
message ElasticsearchCharFilter {
    string name = 1;
    string type = 2;
    string pattern = 3;
    string replacement = 4;
}

// The tokenizer breaks up the string into individual terms or tokens.
message ElasticsearchTokenizer {
    string name = 1;
    string type = 2;
    string delimiter = 3;
    string pattern = 4;
}
